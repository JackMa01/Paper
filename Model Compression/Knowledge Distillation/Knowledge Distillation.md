# Knowledge Distillation

- Junho Yim, Donggyu Joo, Jihoon Bae, Junmo Kim. A Gift from Knowledge Distillation: Fast Optimization, Network Minimization and Transfer Learning. In CVPR. 2017.
  - [[Abstract](https://openaccess.thecvf.com/content_cvpr_2017/html/Yim_A_Gift_From_CVPR_2017_paper.html)] [[Paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Yim_A_Gift_From_CVPR_2017_paper.pdf)] [[Note](https://github.com/JackMa01/PaperNote/blob/main/PaperNote.md#junho-yim-donggyu-joo-jihoon-bae-junmo-kim-a-gift-from-knowledge-distillation-fast-optimization-network-minimization-and-transfer-learning-in-cvpr-2017)]
  
- Yuntao Chen, Naiyan Wang, Zhaoxiang Zhang. DarkRank: Accelerating Deep Metric Learning via Cross Sample Similarities Transfer. In AAAI. 2018.

  - [[Abstract](https://ojs.aaai.org/index.php/AAAI/article/view/11783)] [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/11783/11642)] [[Note](https://github.com/JackMa01/PaperNote/blob/main/PaperNote.md#yuntao-chen-naiyan-wang-zhaoxiang-zhang-darkrank-accelerating-deep-metric-learning-via-cross-sample-similarities-transfer-in-aaai-2018)]

- Sergey Zagoruyko, Nikos Komodakis. Paying more attention to attention: improving the performance of convolutional neural networks via attention transfer. In ICLR. 2017.

  - [[Abstract](https://hal.archives-ouvertes.fr/hal-01832769/)] [[Paper](https://arxiv.org/pdf/1612.03928.pdf)] [[Note](https://github.com/JackMa01/PaperNote/blob/main/PaperNote.md#sergey-zagoruyko-nikos-komodakis-paying-more-attention-to-attention-improving-the-performance-of-convolutional-neural-networks-via-attention-transfer-in-iclr-2017)]

  
